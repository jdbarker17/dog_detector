{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08689ddc",
   "metadata": {},
   "source": [
    "# Dog Model Detector\n",
    "## By: Jon Barker\n",
    "## Date: 15-January-2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72caaee7",
   "metadata": {},
   "source": [
    "This is a model I am working through for my February Machine Learning YouTube series. I will be using the Stanford dogs dataset to train a Convolution Neural Network (CNN) to be able to recognize dog faces and dog breeds. After this model is created, the goal will be to implement this model into a live streaming webcam. With the processing occurring, I want to be able to trigger some type of hardware based around the recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a14b7be",
   "metadata": {},
   "source": [
    "Libraries:\n",
    "\n",
    "This model will be using sklearn, and keras for machine learning processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28970b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import cv2                \n",
    "import matplotlib.pyplot as plt   \n",
    "import sys\n",
    "import os\n",
    "import dlib\n",
    "\n",
    "from skimage import io\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "from sklearn.datasets import load_files\n",
    "\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint  \n",
    "from keras.preprocessing import image                  \n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\n",
    "import np_utils\n",
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73ab9bc",
   "metadata": {},
   "source": [
    "Tensor breakdown:\n",
    "\n",
    "The below functions are used for extracting features from images using different pre-trained deep learning models from the Keras library. Each function is designed to work with a specific model: VGG16, VGG19, ResNet50, Xception, and InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6aa6a206",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_VGG16(tensor):\n",
    "\tfrom keras.applications.vgg16 import VGG16, preprocess_input\n",
    "\treturn VGG16(weights='imagenet', include_top=False).predict(preprocess_input(tensor))\n",
    "\n",
    "def extract_VGG19(tensor):\n",
    "\tfrom keras.applications.vgg19 import VGG19, preprocess_input\n",
    "\treturn VGG19(weights='imagenet', include_top=False).predict(preprocess_input(tensor))\n",
    "\n",
    "def extract_Resnet50(tensor):\n",
    "\tfrom keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "\treturn ResNet50(weights='imagenet', include_top=False).predict(preprocess_input(tensor))\n",
    "\n",
    "def extract_Xception(tensor):\n",
    "\tfrom keras.applications.xception import Xception, preprocess_input\n",
    "\treturn Xception(weights='imagenet', include_top=False).predict(preprocess_input(tensor))\n",
    "\n",
    "def extract_InceptionV3(tensor):\n",
    "\tfrom keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "\treturn InceptionV3(weights='imagenet', include_top=False).predict(preprocess_input(tensor))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26873ed",
   "metadata": {},
   "source": [
    "Dataset Loading:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc46608",
   "metadata": {},
   "source": [
    "This function, `load_dataset`, will process the image and annotation directories to create the required datasets. It uses a label encoder to convert breed names into numerical labels and then onehot-encodes these labels. The function returns the image file paths, the onehot-encoded targets, and the list of dog breed names (dog_names) for the training dataset. The same list is used for the validation and test datasets but is not returned, as the breed names will be the same across all sets.\n",
    "\n",
    "When you run this code, ensure that the paths ('dogImages/train', 'dogImages/valid', 'dogImages/test', and 'annotations/Annotation') match the structure of your dataset. Also, make sure all necessary Python packages (like `glob`, `numpy`, `xml.etree.ElementTree`, `sklearn.preprocessing`, etc.) are installed and imported.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4945cd4b",
   "metadata": {},
   "source": [
    "Currently, I am looking into one specific dataset. Will need to addd functionality to parse through the rest of the folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ffd28f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 total dog categories.\n",
      "There are 152 total dog images.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def load_dataset(image_path, annotation_path):\n",
    "    # Gather image file paths\n",
    "    #image_files = np.array(glob(os.path.join(image_path, \"*/*\")))\n",
    "    \n",
    "     # Gather image file paths\n",
    "    image_files = np.array(glob(os.path.join(image_path, \"*\")))\n",
    "    \n",
    "    # Check if any files are found\n",
    "    if len(image_files) == 0:\n",
    "        print(\"No files found in the directory:\", image_path)\n",
    "        return np.array([]), np.array([]), []\n",
    "\n",
    "    \n",
    "    # Extract breed names and encode labels\n",
    "    breeds = []\n",
    "    for file in image_files:\n",
    "        #print(f\"file = {file}\")\n",
    "        base = os.path.basename(file)\n",
    "        #print(f\"base = {base}\")\n",
    "        #print(f\"Working Directory = {os.getcwd()}\")\n",
    "        xml_file = os.path.join(annotation_path, os.path.splitext(base)[0])\n",
    "        tree = ET.parse(xml_file)\n",
    "        root = tree.getroot()\n",
    "        breed = root.find(\"./object/name\").text\n",
    "        breeds.append(breed)\n",
    "\n",
    "    # Convert breed names into numerical labels\n",
    "    label_encoder = LabelEncoder()\n",
    "    integer_encoded = label_encoder.fit_transform(breeds)\n",
    "\n",
    "    # Onehot-encode the labels\n",
    "    onehot_encoder = OneHotEncoder(sparse=False)\n",
    "    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "    onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "\n",
    "    return image_files, onehot_encoded, label_encoder.classes_\n",
    "\n",
    "# Load train, test, and validation datasets\n",
    "train_files, train_targets, dog_names = load_dataset('dogImages/images/Images/n02085620-Chihuahua/', './dogImages/annotations/Annotation/n02085620-Chihuahua')\n",
    "#valid_files, valid_targets, _ = load_dataset('dogImages/valid', 'annotations/Annotation')\n",
    "#test_files, test_targets, _ = load_dataset('dogImages/test', 'annotations/Annotation')\n",
    "\n",
    "# Print statistics about the dataset\n",
    "print('There are %d total dog categories.' % len(dog_names))\n",
    "print('There are %s total dog images.\\n' % len(np.hstack([train_files])))\n",
    "#print('There are %d training dog images.' % len(train_files))\n",
    "#print('There are %d validation dog images.' % len(valid_files))\n",
    "#print('There are %d test dog images.' % len(test_files))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c9a3fb54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "74e3d953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/jon/Documents/Python/dog_detector/dog_detector'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b71e5000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/dogImages/images/Images/n02085620-Chihuahua/*\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[67], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m np\u001b[38;5;241m.\u001b[39marray(glob(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/dogImages/images/Images/n02085620-Chihuahua/\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m)))\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(os\u001b[38;5;241m.\u001b[39mgetcwd(),\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/dogImages/images/Images/n02085620-Chihuahua/\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m----> 4\u001b[0m \u001b[43mcd\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdogImages/images/Images/n02085620-Chihuahua/\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cd' is not defined"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fb4c671f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jon/Documents/Python/dog_detector/dog_detector\n"
     ]
    }
   ],
   "source": [
    "cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2814f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to load train, test, and validation datasets\n",
    "def load_dataset(path):\n",
    "    data = load_files(path)\n",
    "    dog_files = np.array(data['filenames'])\n",
    "    dog_targets = np_utils.to_categorical(np.array(data['target']), 133)\n",
    "    return dog_files, dog_targets\n",
    "\n",
    "# load train, test, and validation datasets\n",
    "train_files, train_targets = load_dataset('dogImages/images')\n",
    "#valid_files, valid_targets = load_dataset('dogImages/valid')\n",
    "#test_files, test_targets = load_dataset('dogImages/test')\n",
    "\n",
    "# load list of dog names\n",
    "dog_names = [item[20:-1] for item in sorted(glob(\"dogImages/train/*/\"))]\n",
    "\n",
    "# print statistics about the dataset\n",
    "print('There are %d total dog categories.' % len(dog_names))\n",
    "print('There are %s total dog images.\\n' % len(np.hstack([train_files, valid_files, test_files])))\n",
    "print('There are %d training dog images.' % len(train_files))\n",
    "#print('There are %d validation dog images.' % len(valid_files))\n",
    "#print('There are %d test dog images.'% len(test_files))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
